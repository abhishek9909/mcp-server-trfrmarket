Question set using [simple prompts 📝](../questions/README.md).

This is the [query level excelsheet](./) containing links to publicly shareable search results and the comments 📈.

| Question Type                                                                 | Rating and Summary for `while loop` with a mcp server                                                                                                                                  | Rating and Summary for perplexity                                                                                                                                           | Rating and Summary for perplexity pro                                                                                                                                                     |
|------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Questions that were one tool call away (anthropic_onehop) [10]              | Generally accurate with single tool calls but sometimes required additional hops. Some limitations with data recency. **★★★★☆ (4)**                                     | Good at retrieving readily available information with comprehensive answers. Occasionally included irrelevant information. **★★★★☆ (4)**                                     | Similar to basic Perplexity but often provided more detailed answers and better organization of information. Single turn was typically sufficient. **★★★★★ (5)**                            |
| Same Questions that were one tool call away but obfuscated by ChatGPT (chatgpt_obs) [10] | Handled obfuscated queries with no regression from original performance. Maintained accuracy despite slang/informal language. **★★★★☆ (4)**                              | Sometimes misinterpreted questions (e.g., mistaking soccer leagues for basketball). Overall decent but less reliable with obfuscated language. **★★★☆☆ (3)**                  | Better than basic Perplexity at understanding obfuscated queries, but sometimes over-focused on specific teams mentioned as examples. **★★★★☆ (4)**                                         |
| Questions that were two tool calls away (anthropic_twothreehop) [10]        | Handled multi-step reasoning well when tools worked properly. Sometimes faced code execution issues but when successful provided solid analysis. **★★★☆☆ (3)**           | Often provided answers but struggled with questions requiring correlation between multiple data sets. Some answers lacked depth or contained hallucinations. **★★★☆☆ (3)**     | Significantly better with multi-step questions. Used more sources (30–50 pages) and multiple turns. Provided data visualizations and deeper analysis. **★★★★☆ (4)**                         |
| Hard Questions generated by ChatGPT (chatgpt) [20]                           | Made good attempts at complex questions, but often limited by available tools. When successful, provided properly sourced analysis. **★★★☆☆ (3)**                         | Struggled with highly specific questions. Often admitted limitations or provided generic/unsourced answers. Some clear hallucinations. **★★☆☆☆ (2)**                           | Significantly better than basic Perplexity. Used many more sources and multiple turns (sometimes 10+ turns). Still had some limitations with very specific historical data. **★★★★☆ (4)** |

### System Strengths and Weaknesses

| System           | Strengths                                                                                                                                     | Weaknesses                                                                                                                                                |
|------------------|------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **`While Loop` with an MCP server**    | - Direct access to data through tools  <br> - Clear analysis paths  <br> - Honest about limitations                                           | - Sometimes required more tool calls than expected  <br> - Occasional code execution issues                                                                |
| **Perplexity**    | - Quick answers for readily available information  <br> - Good when answers are common knowledge                                             | - Limited depth for complex questions  <br> - Occasional hallucinations  <br> - Struggles with correlating multiple factors                                |
| **Perplexity Pro**| - Significantly more comprehensive  <br> - Uses many more sources  <br> - Better reasoning with multiple turns  <br> - Provides visualizations and tables | - Still sometimes struggled with very specific historical sports data  <br> - Occasionally over-focused on famous players/teams                            |

---

### General Observations

- The **gap between Perplexity and Perplexity Pro widens** as question complexity increases, with Pro showing clear advantages in **multi-step reasoning** and **data correlation**.
- **Informal or obfuscated language** affected **Perplexity's** performance more than the approach using **MCP Server**, suggesting effectiveness of addressing query in natural language is hampered when moving from focused to a more `search engine` like approach.
